{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Missione5.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaziochirale/ContemporaryPython/blob/main/Missione5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dNpFMuwH3ZtN"
      },
      "cell_type": "markdown",
      "source": [
        "# Contemporary Python\n",
        "## Quinta Missione\n",
        "## Il Perceptron\n",
        "\n",
        "Poiché il Perceptron è il più semplice esempio di Rete Neurale, la realizzazione da zero di un programma che permetta di modellare il suo comportamento è particolarmente significativa per comprendere come possa essere sviluppato un software di Machine Learning.\n",
        "\n",
        "Il Perceptron fu presentato per la prima volta nel 1958 da **Frank Rosenblatt**.\n",
        "Rosemblatt immaginava un circuito elettronico (all'epoca non si pensava minimamente di emularlo tramite software) dotato di uno strato d'ingresso ed uno di uscita.\n",
        "\n",
        "La regola di apprendimento è basata sulla minimizzazione dell'errore, la cosiddetta funzione di *error back-propagation* (retro propagazione dell'errore), che in base alla valutazione sull'uscita effettiva della rete, per un dato ingresso, modifica i pesi delle connessioni (corrispondenti alle sinapsi di un neuorone biologico) come **differenza tra l'uscita ottenuta e quella desiderata**.\n",
        "\n",
        "Lo schema logico del Perceptron è illustrato nella figura seguente."
      ]
    },
    {
      "metadata": {
        "id": "Oq1MkW2fzKUx"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.chirale.it/wp-content/uploads/2019/02/Perceptron.jpg)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UFXh3W0w5xEN"
      },
      "cell_type": "markdown",
      "source": [
        "L'entusiasmo iniziale nella comunità scientifica e ingegneristica fu enorme, e alla presentazione del Perceptron si deve la nascita di quella disciplina chiamata *Cibernetica*.\n",
        "\n",
        "Tuttavia, alcuni anni dopo, **Marvin Minsky** e **Seymour Papert**, nel celebre articolo *Perceptrons: An Introduction to Computational Geometry*, dimostrarono che il Perceptron non può essere addestrato per risolvere problemi come ad esempio la ***funzione XOR***. Il Perceptron non può risolvere problemi che non siano di separazione lineare.\n",
        "\n",
        "Questo limite fu da molti erroneamente attribuito a tutte le Reti Neurali, anche se sembra che Papert e Minsky fossero già consapevoli che reti multi-strato di perceptron (*MLP - Multi Layer Perceptron*) possono risolvere problemi più complessi.\n",
        "\n",
        "In ogni caso, anche per il fatto che la potenza di calcolo necessaria ad addestrare strutture MLP non era all'epoca disponibile, la ricerca sulle Reti Neurali subì una battuta d'arresto per poi riprendere dopo oltre un decennio.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Z3Lm4SB59DDS"
      },
      "cell_type": "markdown",
      "source": [
        "## Separazione lineare e non lineare\n",
        "\n",
        "Per comprendere il tipo di problemi di classificazione che un Perceptron è in grado di risolvere possiamo fare riferimento ad un caso semplice, in cui le variabili di input siano solo due. Un Perceptron ha un solo output, normalmente collegato ad una funzione di attivazione di tipo *step*, per cui può assumere solo i valori 0 e 1, è quindi in grado di identificare due categorie.\n",
        "\n",
        "Immaginiamo di rappresentare graficamente i nostri dati utilizzando i due valori di input come valori delle coordinate su un piano cartesiano, e di rappresentare la categoria a cui appartiene un campione attraverso un diverso colore, ciascun campione è quindi rappresentato da un punto colorato collocato su un piano cartesiano.\n",
        "\n",
        "Nella figura che segue vi sono due esempi di dati separabili linearmente e non separabili linearmente.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "spIlTh7E-bar"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.chirale.it/wp-content/uploads/2019/02/LinearSeparability.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "6F-BjfSF_ZaR"
      },
      "cell_type": "markdown",
      "source": [
        "Nel primo caso è possibile individuare una linea retta che separa i due insiemi di campioni, mentre nel secondo caso non è possibile.\n",
        "\n",
        "Un Perceptron può essere addestrato a classificare esclusivamente insiemi di dati che rientrano nel primo tipo."
      ]
    },
    {
      "metadata": {
        "id": "JsH_Ngc6ABLA"
      },
      "cell_type": "markdown",
      "source": [
        "## Programmiamo un Perceptron\n",
        "\n",
        "Nell'esercizio di questa lezione, non utilizzeremo un insieme di dati esistenti, ma svilupperemo una parte di software per generare casualmente un insieme di dati che sia costituito da campioni linearmente separabili e poi utilizzeremo questo generatore di dati per produrre sia i dati di training che i dati di test per verificare che il Perceptron abbia realmente imparato a classificare i dati.\n",
        "\n",
        "Sarà anche l'occasione per imparare ad usare alcune librerie generali del Python molto utilizzate nella pratica.\n",
        "\n",
        "Per rendere il progetto più accattivante utilizzeremo un po' di grafica.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EEy_W70oBcTU"
      },
      "cell_type": "markdown",
      "source": [
        "## La libreria Matplotlib\n",
        "\n",
        "*[Matplotlib](https://matplotlib.org/)* è una libreria che permette di generare in Python grafica 2D in molti formati stampabili e all'interno di ambienti interattivi come i *notebook Jupyter*.\n",
        "\n",
        "Per prima cosa quindi importiamo il modulo ***pyplot*** della libreria attribuendogli il prefisso breve ***pl***.\n"
      ]
    },
    {
      "metadata": {
        "id": "YK1F5mMFyabr"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as pl\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TP1Z_410D-wn"
      },
      "cell_type": "markdown",
      "source": [
        "Definiamo ora una funzione Python che rappresenti una retta su un piano cartesiano.\n",
        "\n",
        "Prendiamo come esempio la retta di equazione: ***y*** = 0,5 \\* ***x*** + 10  \n",
        "\n",
        "La funzione Python sarà quindi una funzione che calcola e restituisce i valori di y per ogni valore dato di x."
      ]
    },
    {
      "metadata": {
        "id": "7U-hOpbQyr14"
      },
      "cell_type": "code",
      "source": [
        "def linea(x):\n",
        "    return 0.5*x + 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAMfGm2UF6vg"
      },
      "cell_type": "markdown",
      "source": [
        "Per disegnare la retta attraverso la libreria *matplotlib* procediamo in questo modo:\n",
        "\n",
        "\n",
        "1.   Inizializziamo due liste vuote per contenere una serie di valori x e la serie dei corrispondenti valori y\n",
        "2.   Generiamo attraverso la funzione *linea()* una serie di coppie x,y e popoliamo le due liste\n",
        "3.   Utilizziamo le funzioni del modulo ***pyplot*** per visualizzare l'insieme di punti come una linea\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GI3XpV76y1Fo"
      },
      "cell_type": "code",
      "source": [
        "lx=[]\n",
        "ly=[]\n",
        "for x in range(-250,250):\n",
        "    y=linea(x)\n",
        "    lx.append(x)\n",
        "    ly.append(y)\n",
        "pl.plot(lx,ly)\n",
        "pl.grid(True)\n",
        "pl.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zm9ij3efMZdQ"
      },
      "cell_type": "markdown",
      "source": [
        "La funzione *plot()* riceve come parametri due liste corrispondenti ad una serie di punti da visualizzare come insieme di segmenti. Se i punti sono allineati tra loro la *plot()* traccerà una linea retta.\n",
        "La funzione *grid()* imposta la visualizzazione della griglia sulla finestra di disegno. Nel nostro caso passiamo il parametro ***True*** e  quindi abilitiamo la griglia.\n",
        "La funzione *show()* apre la finestra con all'interno il grafico tracciato dalla *plot()*.\n",
        "L'intervallo da -250 a +250 è stato scelto come esempio. Può essere ovviamente utilizzato un qualunque altro intervallo."
      ]
    },
    {
      "metadata": {
        "id": "OMBbl83LOSxp"
      },
      "cell_type": "markdown",
      "source": [
        "## Generiamo i dati del nostro problema\n",
        "\n",
        "Definita una qualunque linea, possiamo identificare il nostro problema nel seguente modo: dato un punto qualsiasi, di coordinate (x,y), il punto apparterrà alla categoria \"*rosso*\" se si trova al di sotto della linea retta, mentre apparterrà alla categoria \"*verde*\" se si trova al di sopra.\n",
        "\n",
        "Scriviamo quindi il codice per generare un certo numero di punti a caso e poi disegnarli in rosso o verde in base alla regola stabilita.\n",
        "\n",
        "Avremo bisogno di una nuova libreria per generare numeri casuali. Si tratta della libreria standard ***random***."
      ]
    },
    {
      "metadata": {
        "id": "-LOQDbCaiSQ7"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "def generaPunti(n):\n",
        "    l=[]\n",
        "    for i in range(0, n):\n",
        "        x = random.random()*500-250\n",
        "        y = random.random()*500-250\n",
        "        l.append((x,y))\n",
        "    return l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WnlYL36QiiyM"
      },
      "cell_type": "markdown",
      "source": [
        "La funzione ***random()*** restituisce un numero casuale tra 0 e 1. La funzione ***generaPunti()*** sopra definita, genera un numero n di punti (n passato come parametro) con x e y casuali nell'intervallo -250, +250.\n",
        "\n",
        "Si noti che la lista restituita dalla funzione è una lista di liste, poiché ogni punto è rappresentato da una lista di due valori che sono le sue coordinate.\n",
        "\n",
        "A questo punto possiamo disegnare la retta, generare una lista di un certo numero (ad esempio 100) punti con coordinate casuali ed effettuare il test di posizionamento rispetto alla retta per poi disegnare i punti nel colore appropriato in base alla regola."
      ]
    },
    {
      "metadata": {
        "id": "8LuLSBRskFK7"
      },
      "cell_type": "code",
      "source": [
        "# Disegniamo la retta\n",
        "lx=[]\n",
        "ly=[]\n",
        "for x in range(-250,250):\n",
        "    y=linea(x)\n",
        "    lx.append(x)\n",
        "    ly.append(y)\n",
        "pl.plot(lx,ly)\n",
        "\n",
        "# Creiamo una lista di 100 punti casuali\n",
        "listaPunti = generaPunti(100)\n",
        "\n",
        "# Disegniamo i punti della nostra lista in rosso se si trovano al di\n",
        "# sotto della retta e in verde se si trovano al disopra\n",
        "for punto in listaPunti:\n",
        "    y_linea=linea(punto[0])\n",
        "    if punto[1] > y_linea:\n",
        "        formato = 'go'\n",
        "    else:\n",
        "        formato = 'ro'\n",
        "    pl.plot(punto[0],punto[1],formato)\n",
        "\n",
        "# Mostriamo il disegno complessivo\n",
        "pl.grid(True)\n",
        "pl.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvAgrPFznENi"
      },
      "cell_type": "markdown",
      "source": [
        "Con il codice riportato sopra siamo quindi in grado di generare a piacimento un insieme di dati linearmente separabile di qualunque dimensione.\n",
        "\n",
        "Ovviamente conoscendo l'equazione della retta siamo in grado di determinare in modo assoluto, con un semplice calcolo aritmetico, la categoria dei punti.\n",
        "\n",
        "Quello che faremo nel resto della lezione sarà la realizzazione di un Perceptron che addestreremo per classificare i punti senza avere a disposizione l'equazione della retta!"
      ]
    },
    {
      "metadata": {
        "id": "JcLnsbtbpZr5"
      },
      "cell_type": "markdown",
      "source": [
        "## Definiamo il Perceptron\n",
        "\n",
        "Un modo elegante per definire un Perceptron in Python è quello di utilizzare la programmazione *object oriented* e definire una *classe* specifica per rappresentare oggetti di tipo Perceptron.\n",
        "\n",
        "Un Perceptron può avere un numero arbitrario di input, ha un solo output e funzione di attivazione che solitamente è la funzione *step* con valori in output  -1 oppure 1.\n",
        "\n",
        "Nel nostro caso definiamo la classe in modo generico, cioè manteniamo la definizione sufficientemente generale da poter essere utilizzata anche in altri casi, non solo nell'esempio bidimensionale che stiamo trattando.\n",
        "\n",
        "Dovremo definire un inizializzatore e i principali attributi e metodi che ci aspettiamo che caratterizzino un Perceptron.\n",
        "\n",
        "Un buon esempio è il seguente.\n"
      ]
    },
    {
      "metadata": {
        "id": "YMf1FkCZqj7D"
      },
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    # L'inizializzatore crea l'oggetto Perceptron e inizializza casualmente i pesi\n",
        "    def __init__(self, learn_speed, num_inputs):\n",
        "        self.speed = learn_speed\n",
        "        self.weights = []\n",
        "        for x in range(0, num_inputs):\n",
        "            self.weights.append(random.random()*2-1)\n",
        "\n",
        "    # Definiamo la funzione di attivazione in questo modo:\n",
        "    # trasformiamo i valori maggiori di 0 in 1, and quelli minori di 0 in -1\n",
        "    def activate(self, num):\n",
        "        if num > 0:\n",
        "            return 1\n",
        "        return -1\n",
        "\n",
        "    # Definiamo la funzione per effettuare la previsione dell'output\n",
        "    def feed_forward(self, inputs):\n",
        "        sum = 0\n",
        "        # Effettuiamo la sommatoria dei valori di input moltiplicati per i pesi\n",
        "        for x in range(0, len(self.weights)):\n",
        "            sum += self.weights[x] * inputs[x]\n",
        "        # Richiamiamo la funzione di attivazione passando la sommatoria e restituiamo l'output\n",
        "        return self.activate(sum)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "07QpOGwIrQA6"
      },
      "cell_type": "markdown",
      "source": [
        "L'inizializzatore riceve come parametri il numero di input del Perceptron e un valore, chiamato *learn_speed* che sarà utilizzato per modulare la funzione di apprendimento che scriveremo più avanti.\n",
        "\n",
        "I pesi relativi alle connessioni  tra gli input e il nucleo del neurone vengono inizializzati in modo casuale, come previsto dalla teoria, nel nostro caso con valori tra -1 e 1. I pesi sono registrati all'interno di una lista e sono ovviamente corrispondenti al numero di input indicati nella chiamata all'inizializzatore.\n",
        "\n",
        "La funzione  *feed_forward()* è il metodo dell'oggetto Perceptron che deve essere invocato per effettuare una classificazione su un determinato input. Come si vede dal codice effettua la sommatoria pesata degli input e poi fornisce in output il valore passato alla funzione di attivazione sopra definita *activate()*.\n",
        "\n",
        "Per il momento non abbiamo affrontato il problema dell'addestramento che vedremo più avanti.\n",
        "\n",
        "Prima, infatti, vediamo  come creare un oggetto Perceptron adatto al nostro esempio e come utilizzarlo per effettuare delle previsioni sui dati. Non essendo ancora addestrato il Perceptron fornirà risposte casuali, ma ci serve come test di funzionamento della parte scritta finora."
      ]
    },
    {
      "metadata": {
        "id": "C5W-x7bDwaH1"
      },
      "cell_type": "markdown",
      "source": [
        "Per prima cosa creiamo un oggetto Perceptron chiamato p.\n",
        "\n",
        "Nel nostro esempio, gli input sono le due coordinate x e y del punto che intendiamo classificare, per cui il Perceptron dovrebbe avere 2 input.\n",
        "\n",
        "Tuttavia, come sarà spiegato più avanti, per assicurare la convergenza durante la fase di training **è spesso necessario aggiungere un ulteriore input** di valore sempre costante, **scelto ad un valore fisso che solitamente è 1 o -1**. Questo ulteriore input, che non appartiene allo spazio del problema è chiamato ***BIAS*** ed è molto utilizzato nelle reti neurali.\n",
        "\n",
        "Pertanto il nostro Perceptron dovrà avere 3 input. Come parametro *learn_speed* si utilizzano solitamente valori molto piccoli."
      ]
    },
    {
      "metadata": {
        "id": "aBixZl3bvjht"
      },
      "cell_type": "code",
      "source": [
        "# Creiamo un Perceptron\n",
        "p = Perceptron(0.01,3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWEHLvy9xrGn"
      },
      "cell_type": "markdown",
      "source": [
        "Una volta creato l'oggetto p di tipo Perceptron con 2 input + il bias, possiamo provare a generare un centinaio di punti casuali e a fornire le relative coordinate al metodo *feed_forward(*) del Perceptron per poi disegnarli in verde o in rosso a seconda del valore restituito.\n",
        "\n",
        "Si noti che oltre alle due coordinate, al metodo feed_forward() deve essere passato anche il valore costante di *bias*, poiché la funzione si aspetta tre parametri."
      ]
    },
    {
      "metadata": {
        "id": "teSjR_Czy62P"
      },
      "cell_type": "code",
      "source": [
        "# Creiamo una lista di 100 punti casuali\n",
        "listaPunti = generaPunti(100)\n",
        "\n",
        "# Disegniamo la retta\n",
        "lx=[]\n",
        "ly=[]\n",
        "for x in range(-250,250):\n",
        "    y=linea(x)\n",
        "    lx.append(x)\n",
        "    ly.append(y)\n",
        "pl.plot(lx,ly)\n",
        "\n",
        "# Disegniamo i punti della nostra lista in rosso se il perceptron fornisce -1\n",
        "# in verde se il perceptron fornisce 1\n",
        "for punto in listaPunti:\n",
        "    guess=p.feed_forward([punto[0],punto[1],1])\n",
        "    if guess == 1:\n",
        "        formato = 'go'\n",
        "    else:\n",
        "        formato = 'ro'\n",
        "    pl.plot(punto[0],punto[1],formato)\n",
        "\n",
        "# Mostriamo il disegno complessivo\n",
        "pl.grid(True)\n",
        "pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzW2G1Rjzhy7"
      },
      "cell_type": "markdown",
      "source": [
        "Eseguendo il codice più volte è possibile rendersi conto che il Perceptron classifica in modo casuale e solo raramente sembra indovinare il posizionamento dei punti."
      ]
    },
    {
      "metadata": {
        "id": "0rsAlaF8z5MI"
      },
      "cell_type": "markdown",
      "source": [
        "## Apprendimento\n",
        "\n",
        "Passiamo ora alla parte più interessante e vediamo come sia possibile dotare l'oggetto Perceptron della capacità di apprendimento.\n",
        "\n",
        "Prima di definire la funzione che consentirà l'addestramento del Perceptron, abbiamo bisogno di individuare un insieme di dati noti, da utilizzare come base per l'addestramento.\n",
        "\n",
        "Un *dataset* di *training* è solitamente composto da un insieme di dati opportunamente etichettati. Le etichette o *label* associate ad ogni campione identificano la corretta classificazione del campione.\n",
        "\n",
        "Procediamo quindi a generare un certo numero di punti sul nostro piano bidimensionale e provvediamo ad etichettarli utilizzando le formule viste all'inizio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creiamo una lista di 100.000 punti casuali\n",
        "listaPunti = generaPunti(100000)\n",
        "\n",
        "# Creaiamo una lista vuota per contenere il dataset comprendente le etichette\n",
        "dataSet = []\n",
        "\n",
        "# Etichettiamo i punti utilizzando la funzione che verifica la posizione rispetto alla retta\n",
        "# e costruiamo il dataSet come lista di tuple. Ogni tupla ha due elementi un punto e una etichetta\n",
        "for punto in listaPunti:\n",
        "    y_linea=linea(punto[0])\n",
        "    if punto[1] > y_linea:\n",
        "        label = 'go'\n",
        "    else:\n",
        "        label = 'ro'\n",
        "    dataSet.append((punto,label))"
      ],
      "metadata": {
        "id": "_qfk59aLelJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nostro ***dataSet*** è memorizzato in un modo abbastanza comune in questo tipo di applicazioni. Si tratta di una **lista di tuple**. Ogni tupla, elemento della lista ***dataSet***, ha due elementi, il primo elemento è nuovamente una tupla, rappresentante un punto dello spazio bidimensionale, il secondo elemento è una stringa valorizzata con l'etichetta associata al punto.\n",
        "\n",
        "Per rendersi conto di questa struttura, basta chiedere una *print* dei primi 10 elementi di ***dataSet***"
      ],
      "metadata": {
        "id": "wo6uPtwary21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataSet[:10])"
      ],
      "metadata": {
        "id": "81xss0gQq5y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora che abbiamo preparato il nostro *dataset* diamo uno sguardo ai dati visualizzandoli sul piano.\n"
      ],
      "metadata": {
        "id": "xgZpJ_drs5Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disegnamo la retta di riferimento\n",
        "lx=[]\n",
        "ly=[]\n",
        "for x in range(-250,250):\n",
        "    y=linea(x)\n",
        "    lx.append(x)\n",
        "    ly.append(y)\n",
        "pl.plot(lx,ly)\n",
        "\n",
        "# Disegniamo i primi 100 punti della nostra lista in rosso o in verde sulla base delle label\n",
        "i = 0\n",
        "while i<100:\n",
        "    pl.plot(dataSet[i][0][0],dataSet[i][0][1],dataSet[i][1])\n",
        "    i +=1\n",
        "\n",
        "# Mostriamo il disegno complessivo\n",
        "pl.grid(True)\n",
        "pl.show()"
      ],
      "metadata": {
        "id": "PTqaydkstHO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Come si vede dalla figura, il campione estratto mostra che i dati sono correttamente etichettati.\n",
        "\n",
        "Nel nostro caso, il dataset è stato generato da noi usando la funzione random. In un caso di applicazione reale, il dataset proviene da un campione di dati di cui si conosce la classificazione.\n",
        "\n",
        "Prima di utilizzare l'intero dataset per addestrare la rete, è opportuno fare una considerazione.\n",
        "\n",
        "Quando si addestra un classificatore, è importante che questo impari effettivamente a risolvere il problema e non semplicemente a riconoscere correttamente i soli dati forniti come esempio.\n",
        "\n",
        "Esiste infatti il problema dell'***overfitting***, in cui praticamente il classificatore si limita a memorizzare i dati di training ma poi non riesce a classificare correttamente dati che non fanno parte dell'insieme di training.\n",
        "\n",
        "Per essere sicuri che il nostro classificatore abbia raggiunto una competenza generale sul problema, è opportuno tenere da parte un sottoinsieme dei dati etichettati che abbiamo a disposizione, in modo da non utilizzarli in fase di training, ma utilizzarli successivamente per verificare l'efficacia dell'addestramento.\n",
        "\n",
        "In questo modo, potremo effettuare un test utilizzando dati che il nostro Perceptron non ha mai visto prima.\n",
        "\n",
        "Creaiamo quindi due dataset, uno da utilizzare per il training e uno da utilizzare per il test, a partire dal nostro campione.\n",
        "\n",
        "Una regola euristica solitamente utilizzata è quella di suddividere il campione di dati noti riservando l'80% dei dati per il training e il restante 20% per il test.\n",
        "\n",
        "Prendiamo quindi come insieme di training tutti i dati di ***dataSet*** tranne gli ultimi 20.000 che manterremo da parte per poi effettuare il test.\n",
        "\n",
        "Un modo semplice e diretto per creare i due insiemi etichettati è il seguente."
      ],
      "metadata": {
        "id": "5Zou6pgzvOPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creiamo i due dataset di training e di test\n",
        "trainingSet = dataSet[:-20000] # Prende tutto tranne gli ultimi 20.000 elementi\n",
        "testSet = dataSet[-20000:] # Prende solo gli ultimi 20.000 elementi\n",
        "\n"
      ],
      "metadata": {
        "id": "XhpYFEiGydP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora che abbiamo preparato i due insiemi di dati, il dataset di training e il dataset di test, possiamo procedere ad implementare la funzione di apprendimento del nostro Perceptron.\n",
        "\n",
        "Per fare questo, è sufficiente aggiungere alla definizione della classe Perceptron il metodo *back_propagation()* che implementa l'algoritmo di training.\n",
        "\n",
        "Solitamente, nell'implementazione delle funzioni di questo tipo, oltre alla parte matematica che implementa l'algoritmo, vengono aggiunte delle funzionalità per consentire il monitoraggio della fase di training in modo da capire durante l'esecuzione come stanno andando le cose.\n",
        "\n",
        "Nel nostro caso ci limiteremo a contare il numero di errori compiuti sui dati passati in fase di training, per cui la funzione di *back propagation* restituirà un valore pari a 0 o ad 1 a seconda se il campione è stato correttamente classificato oppure no (e quindi sono stati modificati i pesi).\n",
        "\n",
        "La definizione completa della classe Perceptron diventa quella seguente."
      ],
      "metadata": {
        "id": "krS8cuxiel41"
      }
    },
    {
      "metadata": {
        "id": "R8xyQsEh1mSA"
      },
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learn_speed, num_inputs):\n",
        "        self.speed = learn_speed\n",
        "        self.weights = []\n",
        "        for x in range(0, num_inputs):\n",
        "            self.weights.append(random.random()*2-1)\n",
        "\n",
        "    # Activation function\n",
        "    def activate(self, num):\n",
        "        if num > 0:\n",
        "            return 1\n",
        "        return -1\n",
        "\n",
        "    # Forward propagation\n",
        "    def feed_forward(self, inputs):\n",
        "        sum = 0\n",
        "        for x in range(0, len(self.weights)):\n",
        "            sum += self.weights[x] * inputs[x]\n",
        "        return self.activate(sum)\n",
        "\n",
        "    # Back propagation\n",
        "    def back_propagation(self, inputs, desired_output):\n",
        "        guess = self.feed_forward(inputs)   # Calcolo il valore di output relativo agli input forniti\n",
        "        error = desired_output - guess      # Calcolo l'errore come differenza tra valore in output e valore atteso\n",
        "        # La correzione dei pesi avviene secondo la formula\n",
        "        # peso = peso + errore*valore_input*learn_speed\n",
        "        # se l'errore è pari a zero la formula non altera il valore del peso\n",
        "        for x in range(0, len(self.weights)):\n",
        "            self.weights[x] += error*inputs[x]*self.speed\n",
        "        # Restituiamo 0 se la previsione è stata corretta, 1 altrimenti\n",
        "        # questo dato servirà più avanti per conteggiare gli errori durante il processo di apprendimento\n",
        "        if error == 0:\n",
        "            return(0)\n",
        "        else:\n",
        "            return(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bF_oKpx118k0"
      },
      "cell_type": "markdown",
      "source": [
        "Come è spiegato nei commenti nel codice, la funzione di errore scelta è la semplice differenza tra il valore atteso e quello stimato. La formula di correzione dei pesi non effettua alcuna variazione se l'errore è zero, mentre modifica il peso di un valore proporzionale al valore dell'input e al valore dell'errore se questo non è nullo. Si noti che il parametro *learn_speed* è il coefficiente di proporzionalità."
      ]
    },
    {
      "metadata": {
        "id": "0RofCjmn3kei"
      },
      "cell_type": "markdown",
      "source": [
        "A questo punto potremmo procedere all'addestramento del nostro Perceptron.\n",
        "\n",
        "Nel caso in esame la rete è molto semplice, poiché è costituita dal neurone stesso, ma nelle applicazioni di Deep Learning la rete è in realtà composta da molti neuroni opportunamente interconnessi.\n",
        "\n",
        "Nelle applicazioni di machine learning la rete neurale, chiamata spesso *modello*, è l'oggetto che svolge la funzione desiderata. I neuroni sono i suoi componenti interni.\n",
        "\n",
        "Per abituarci sin d'ora allo sviluppo di applicazioni di questo tipo, procederemo a modellare una Rete Neurale utilizzando una nuova classe che conterrà tutto ciò che serve per svolgere le tipiche operazioni di una Rete Neurale. Chiamiamo questa classe NeuralNet.\n",
        "\n",
        "La classe NeuralNet rappresenta il ***modello*** di rete neurale che risolve il nostro problema.\n",
        "\n",
        "Un oggetto di tipo ***NeuralNet*** contiene al suo interno un solo neurone, quindi un oggetto della classe ***Perceptron***, e possiede tutti i metodi necessari ad effettuare e monitorare il processo di addestramento e le operazioni di classificazione."
      ]
    },
    {
      "metadata": {
        "id": "fC6DDvNc3_q4"
      },
      "cell_type": "code",
      "source": [
        "class NeuralNet:\n",
        "    # L'inizializzatore crea l'attributo \"perceptron\" come oggetto di tipo Perceptron con 3 input e speed 0.01\n",
        "    def __init__(self):\n",
        "        self.perceptron = Perceptron(0.01 , 3 )\n",
        "\n",
        "    def classify(self, point):\n",
        "      answer = self.perceptron.feed_forward([point[0],point[1],1])\n",
        "      if answer == -1:\n",
        "        return 'ro'\n",
        "      else:\n",
        "        return 'go'\n",
        "\n",
        "\n",
        "    def train(self, trainSet, epoch):\n",
        "      # Ripete il ciclo di training per un numero di volte pari ad epoch\n",
        "        for i in range(0,epoch):\n",
        "            random.shuffle(trainSet) # Rimescoliamo casualmente i dati ad ogni epoca\n",
        "            errTot = 0 # Il conteggio (monitoraggio) degli errori riparte da zero ad ogni nuova epoca\n",
        "            for x in trainSet:\n",
        "              if x[1] == 'go':\n",
        "                answer = 1\n",
        "              else:\n",
        "                answer = -1\n",
        "              inputs = [x[0][0],x[0][1],1]\n",
        "              # Chiamiamo la funzione di back propagation e incrementiamo il conteggio errori\n",
        "              errTot+=self.perceptron.back_propagation(inputs, answer)\n",
        "            # Al termine del sottociclo di 100.000 punti visualizziamo il valore del contatore errori\n",
        "            print(\"Iterazione:\",i,\"Errori:\",errTot)\n",
        "\n",
        "    def evaluate(self, tSet):\n",
        "        errori = 0\n",
        "        for x in tSet:\n",
        "          inputs = [x[0][0],x[0][1],1]\n",
        "          if x[1] == 'go':\n",
        "            correctAnswer = 1\n",
        "          else:\n",
        "            correctAnswer = -1\n",
        "          if self.perceptron.feed_forward(inputs) != correctAnswer:\n",
        "            errori +=1\n",
        "        return 1-(errori/len(tSet))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZlcJc9r34-hL"
      },
      "cell_type": "markdown",
      "source": [
        "La classe **NeuralNet** rappresenta quindi un modello di classificatore con un solo neurone di tipo *Perceptron* con due input numerici e una sola uscita binaria.\n",
        "\n",
        "Per risolvere un problema di classificazione binaria, con input bidimensionale, linearmente separato, in pratica qualunque problema matematicamente riducibile all'esempio dei punti sopra e sotto la retta che abbiamo visto finora, è sufficiente:\n",
        "\n",
        "\n",
        "\n",
        "*   disporre di un campione di dati noti\n",
        "*   creare la rete istanziando un oggetto della classe NeuralNet\n",
        "*   addestrare la rete con una parte dei dati del campione\n",
        "*   verificare la qualità raggiunta dalla rete addestrata utilizzando il sottoinsieme di dati noti non impiegati nell'addestramento\n",
        "*   perfezionare eventualmente l'addestramento fino al raggiungimento delle prestazioni desiderate\n",
        "*  utilizzare la rete per classificare i nuovi dati\n",
        "\n",
        "La classe NeuralNet permette di svolgere tutte queste operazioni attraverso i suoi metodi:\n",
        "\n",
        "**train(trainSet, epoch)** Effettua il training della rete utilizzando *trainSet* per un numero di cicli (epoche) pari ad *epoch*\n",
        "\n",
        "**evaluate(tSet)** Restituisce la percentuale di elementi di *tSet* correttamente classificati. Questa metrica si chiama accuracy\n",
        "\n",
        "**classify(point)** Classifica un punto restituendo l'etichetta di colore\n",
        "\n",
        "Il metodo **train** riceve in input il *dataset* da utilizzare per l'addestramento e il parametro *epoch*.\n",
        "\n",
        "L'intera sequenza costituita dai dati di training viene sottoposta al metodo di back_propagation più volte. Ciascun ciclo è chiamato *epoca*.\n",
        "\n",
        "Attraverso il parametro *epoch* possiamo stabilire il numero di cicli, cioè di epoche, che vogliamo far eseguire al metodo *train*.\n",
        "\n",
        "Durante ogni ciclo, l'algoritmo di back_propagation modifica i parametri della rete. Sottoponendo più volte gli stessi dati di training, i parametri continuano ad essere modificati e la rete dovrebbe continuare a migliorare le sue prestazioni. Questo fenomeno viene definito *convergenza*.\n",
        "\n",
        "Se prima di ogni ciclo, il dataset di training viene *rimescolato*, in modo da cambiare l'ordine dei dati nella sequenza, il training risulta più efficace.\n",
        "\n",
        "Per questo motivo è stata inserita l'istruzione *shuffle* all'inizio di ogni nuovo ciclo.\n",
        "\n",
        "\n",
        "Procediamo quindi a creare la rete.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-EgID1Eo5Hfd"
      },
      "cell_type": "code",
      "source": [
        "rete = NeuralNet()\n",
        "print(\"Ho creato la rete\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La rete neurale è stata creata, ma al momento i pesi sulle sue connessioni neurali sono valori puramente casuali.\n",
        "\n",
        "Se proviamo a chiamare il metodo ***evaluate()*** utilizzando il dataset di test otterremo probabilmente una scarsa percentuale di classificazioni corrette.\n",
        "\n",
        "Potrebbe anche darsi che casualmente la rete abbia già delle buone prestazioni. In questo caso si tratterebbe semplicemente di una pura casualità. Se la metrica è superiore all'85% possiamo rieseguire la cella precedente creando una nuova rete casuale."
      ],
      "metadata": {
        "id": "YVhOLhVZqV5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{rete.evaluate(testSet) * 100:.2f}%')"
      ],
      "metadata": {
        "id": "Yt4X8xVy-B44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsRtVNI05fuf"
      },
      "cell_type": "markdown",
      "source": [
        "Se le prestazini della rete sono inferiori all'85% possiamo procedere all'addestramento, altrimenti, per vedere meglio l'effetto conviene rigenerare la rete in modo da partire con una configurazione che mostri prestazioni più scarse.\n",
        "\n",
        "Proviamo con 300 epoche, cioè verranno sottoposti tutti i dati di training ripetutamente per 300 volte."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rete.train(trainingSet,300)"
      ],
      "metadata": {
        "id": "Coz0p5Fzsu16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Come si vede dal monitoraggio, il numero di errori riscontrato ad ogni nuova epoca e quindi le prestazioni sui dati di training hanno un andamento convergente.\n",
        "\n",
        "La rete apprende e migliora le sue prestazioni!\n",
        "\n",
        "Proviamo quindi a rivalutare le prestazioni sui dati che non ha mai visto prima."
      ],
      "metadata": {
        "id": "sjSUWsO8t2_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{rete.evaluate(testSet) * 100:.2f}%')"
      ],
      "metadata": {
        "id": "AJYQY6wvubx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Molto meglio, vero?\n",
        "\n",
        "Realizziamo un programmino per vedere la rete in azione su un insieme casuale di nuovi punti."
      ],
      "metadata": {
        "id": "fDRfe_NpupFV"
      }
    },
    {
      "metadata": {
        "id": "dZHH-aQW5x69"
      },
      "cell_type": "code",
      "source": [
        "# Disegniamo la retta\n",
        "lx=[]\n",
        "ly=[]\n",
        "for x in range(-250,250):\n",
        "    y=linea(x)\n",
        "    lx.append(x)\n",
        "    ly.append(y)\n",
        "pl.plot(lx,ly)\n",
        "\n",
        "# Creiamo una lista di 1000 punti casuali\n",
        "listaPunti = generaPunti(1000)\n",
        "\n",
        "# Disegniamo i punti della nostra lista nel colore fornito dal nostro classificatore\n",
        "for punto in listaPunti:\n",
        "    formato = rete.classify(punto)\n",
        "    pl.plot(punto[0],punto[1],formato)\n",
        "\n",
        "# Mostriamo il disegno complessivo\n",
        "pl.grid(True)\n",
        "pl.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMal8VZk6DdJ"
      },
      "cell_type": "markdown",
      "source": [
        "Come si vede, la nostra rete è un perfetto classificatore adeguato a risolvere il nostro problema."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzBRSVHUx6JU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}